{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c94d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HashEmbedder(nn.Module):\n",
    "    def __init__(self, bounding_box, n_levels=16, n_features_per_level=2,\\\n",
    "                log2_hashmap_size=19, base_resolution=16, finest_resolution=512):\n",
    "        super(HashEmbedder, self).__init__()\n",
    "        self.bounding_box = bounding_box\n",
    "        self.n_levels = n_levels                                  # 多少个级别的hashmap，对应论文中的L\n",
    "        self.n_features_per_level = n_features_per_level          # hashmap中的每个特征的维度，对应论文中的F\n",
    "        self.log2_hashmap_size = log2_hashmap_size                # 每个hashmap中有多少个特征（2的指数次个），对应论文中的T\n",
    "        self.base_resolution = torch.tensor(base_resolution)\n",
    "        self.finest_resolution = torch.tensor(finest_resolution)\n",
    "        self.out_dim = self.n_levels * self.n_features_per_level\n",
    "\n",
    "        self.b = torch.exp((torch.log(self.finest_resolution)-torch.log(self.base_resolution))/(n_levels-1))\n",
    "\n",
    "        # nn.Embedding(num_embeddings, embedding_dim)创建了一个Lookup table, 用来实现hashmap\n",
    "        # Parameters:\n",
    "        # num_beddings: 特征的数量 embedding_dim：每个特征的维度\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(2**self.log2_hashmap_size, \\\n",
    "                                        self.n_features_per_level) for i in range(n_levels)])\n",
    "        # custom uniform initialization\n",
    "        for i in range(n_levels):\n",
    "            nn.init.uniform_(self.embeddings[i].weight, a=-0.0001, b=0.0001)\n",
    "            # self.embeddings[i].weight.data.zero_()\n",
    "        \n",
    "\n",
    "    def trilinear_interp(self, x, voxel_min_vertex, voxel_max_vertex, voxel_embedds):\n",
    "        '''\n",
    "        x: B x 3\n",
    "        voxel_min_vertex: B x 3\n",
    "        voxel_max_vertex: B x 3\n",
    "        voxel_embedds: B x 8 x 2\n",
    "        '''\n",
    "        # source: https://en.wikipedia.org/wiki/Trilinear_interpolation\n",
    "        weights = (x - voxel_min_vertex)/(voxel_max_vertex-voxel_min_vertex) # B x 3\n",
    "\n",
    "        # step 1\n",
    "        # 0->000, 1->001, 2->010, 3->011, 4->100, 5->101, 6->110, 7->111\n",
    "        c00 = voxel_embedds[:,0]*(1-weights[:,0][:,None]) + voxel_embedds[:,4]*weights[:,0][:,None]\n",
    "        c01 = voxel_embedds[:,1]*(1-weights[:,0][:,None]) + voxel_embedds[:,5]*weights[:,0][:,None]\n",
    "        c10 = voxel_embedds[:,2]*(1-weights[:,0][:,None]) + voxel_embedds[:,6]*weights[:,0][:,None]\n",
    "        c11 = voxel_embedds[:,3]*(1-weights[:,0][:,None]) + voxel_embedds[:,7]*weights[:,0][:,None]\n",
    "\n",
    "        # step 2\n",
    "        c0 = c00*(1-weights[:,1][:,None]) + c10*weights[:,1][:,None]\n",
    "        c1 = c01*(1-weights[:,1][:,None]) + c11*weights[:,1][:,None]\n",
    "\n",
    "        # step 3\n",
    "        c = c0*(1-weights[:,2][:,None]) + c1*weights[:,2][:,None]\n",
    "\n",
    "        return c\n",
    "    \n",
    "    def hash(self, coords, log2_hashmap_size):\n",
    "        '''\n",
    "        coords: this function can process upto 7 dim coordinates\n",
    "        log2T:  logarithm of T w.r.t 2\n",
    "        '''\n",
    "        primes = [1, 2654435761, 805459861, 3674653429, 2097192037, 1434869437, 2165219737]\n",
    "\n",
    "        xor_result = torch.zeros_like(coords)[..., 0] # 任何数与0做位异或操作结果都是这个数本身!\n",
    "        for i in range(coords.shape[-1]):\n",
    "            xor_result ^= coords[..., i]*primes[i]    # python中^是按位异或运算符，运算规则是：将两个数的二进制按位对比，如果相同（都为1或者都为0），则运算结果的对应位上是0，否则为1\n",
    "\n",
    "        return torch.tensor((1<<log2_hashmap_size)-1).to(xor_result.device) & xor_result # 1 << log2_hashmap_size代表将1的二进制左移log2_hashmap_size位，然后在其右边全补上0，将结果换算为十进制等于2的log2_hashmap_size次方\n",
    "                                                                                        # 2的N次方-1在二进制中是一个十分特殊的数，它右N个1从最右向左依次排列组成\n",
    "                                                                                        \n",
    "                                                                                        # python中&是位与运算符，运算规则是：将两个数的二进制按位对比，都为1，则结果的对应位上是1，否则为0\n",
    "                                                                                        # 对于一个数x（十进制），x mod 2的N次方 等价于取x的二进制的后N位数（得到的是二进制，需要将其转化为十进制）\n",
    "                                                                                        # 例如，对109（十进制），x mod 2的4次方(16) = 13:\n",
    "                                                                                        # 109的二进制为1101101\n",
    "                                                                                        #  13的二进制为   1101\n",
    "                                                                                        # 因此这行代码等效于 xor_result mod 2的log2_hashmap_size\n",
    "\n",
    "    def get_voxel_vertices(self, xyz, bounding_box, resolution, log2_hashmap_size):\n",
    "        '''\n",
    "        xyz: 3D coordinates of samples. B x 3\n",
    "        bounding_box: min and max x,y,z coordinates of object bbox\n",
    "        resolution: number of voxels per axis\n",
    "        '''\n",
    "        box_min, box_max = bounding_box.to(xyz.device)\n",
    "        BOX_OFFSETS = torch.tensor([[[i,j,k] for i in [0, 1] for j in [0, 1] for k in [0, 1]]]).to(xyz.device)\n",
    "        \n",
    "        keep_mask = xyz==torch.max(torch.min(xyz, box_max), box_min)\n",
    "        if not torch.all(xyz <= box_max) or not torch.all(xyz >= box_min):\n",
    "            # print(\"ALERT: some points are outside bounding box. Clipping them!\")\n",
    "            xyz = torch.clamp(xyz, min=box_min, max=box_max)\n",
    "\n",
    "        grid_size = (box_max-box_min)/resolution\n",
    "        \n",
    "        bottom_left_idx = torch.floor((xyz-box_min)/grid_size).int() # bottom_left_idx.shape = [B, 3]\n",
    "        voxel_min_vertex = bottom_left_idx*grid_size + box_min\n",
    "        voxel_max_vertex = voxel_min_vertex + torch.tensor([1.0,1.0,1.0]).to(xyz.device)*grid_size\n",
    "\n",
    "        voxel_indices = bottom_left_idx.unsqueeze(1) + BOX_OFFSETS # shape: [B, 1, 3] +　[1, 8, 3]\n",
    "        hashed_voxel_indices = self.hash(voxel_indices, log2_hashmap_size)\n",
    "\n",
    "        return voxel_min_vertex, voxel_max_vertex, hashed_voxel_indices, keep_mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is 3D point position: B x 3\n",
    "        x_embedded_all = []\n",
    "        for i in range(self.n_levels):\n",
    "            resolution = torch.floor(self.base_resolution * self.b**i)\n",
    "            voxel_min_vertex, voxel_max_vertex, hashed_voxel_indices, keep_mask = self.get_voxel_vertices(\\\n",
    "                                                x, self.bounding_box, \\\n",
    "                                                resolution, self.log2_hashmap_size)\n",
    "            \n",
    "            voxel_embedds = self.embeddings[i](hashed_voxel_indices)\n",
    "\n",
    "            x_embedded = self.trilinear_interp(x, voxel_min_vertex, voxel_max_vertex, voxel_embedds)\n",
    "            x_embedded_all.append(x_embedded)\n",
    "\n",
    "        keep_mask = keep_mask.sum(dim=-1)==keep_mask.shape[-1]\n",
    "        return torch.cat(x_embedded_all, dim=-1), keep_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eaeb05",
   "metadata": {},
   "source": [
    "1. 设置测试函数，生成训练集与测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82868f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of available GPU: 3\n",
      "GPU0: NVIDIA GeForce RTX 3090\n",
      "GPU1: NVIDIA GeForce RTX 3090\n",
      "GPU2: NVIDIA GeForce RTX 3090\n",
      "[cuda:0] on!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print('The number of available GPU:',torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f'GPU{i}: {torch.cuda.get_device_name(i)}')\n",
    "\n",
    "Device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'[{Device}] on!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6446f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def TestFunction(x):\n",
    "    '''\n",
    "    x is 3D points position B x 3\n",
    "    '''\n",
    "    # result = torch.sin(torch.pi*x[..., 0]) + torch.cos(torch.pi*x[..., 1]) + torch.sin(2*torch.pi*x[..., 2])\n",
    "    # result = torch.sqrt(x[..., 0]**2 + x[..., 0]**2 + x[..., 2]**2)\n",
    "    result = x[..., 0 ] + x[..., 1]+ x[..., 2]\n",
    "    return result\n",
    "\n",
    "bounding_box = torch.tensor([[-5, -5, -5], [5, 5, 5]])\n",
    "\n",
    "def get_dataset(bouding_box, batch_size = 100, noise_std = 0.01):\n",
    "    coords_min = bouding_box[0]\n",
    "    coords_max = bouding_box[1]\n",
    "    length = coords_max - coords_min\n",
    "    weight = torch.rand([batch_size, 3])\n",
    "    coords = coords_min + length * weight\n",
    "    \n",
    "    real_value = TestFunction(coords)\n",
    "    noise = torch.randn(real_value.shape) * noise_std\n",
    "    value_withNoisy = real_value + noise\n",
    "    \n",
    "    return coords, value_withNoisy\n",
    "\n",
    "trainDataset_inputs, trainDataset_outputs = get_dataset(bounding_box, batch_size = 10000)\n",
    "testDataset_inputs, testDataset_outputs = get_dataset(bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc09aec",
   "metadata": {},
   "source": [
    "2. 神经网络构建与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba208f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-GPU training!\n",
      "Epoch [2/100], Test Loss: 25.4057\n",
      "Epoch [4/100], Test Loss: 5.3855\n",
      "Epoch [6/100], Test Loss: 3.0039\n",
      "Epoch [8/100], Test Loss: 2.4395\n",
      "Epoch [10/100], Test Loss: 2.3806\n",
      "Epoch [12/100], Test Loss: 2.4087\n",
      "Epoch [14/100], Test Loss: 2.4200\n",
      "Epoch [16/100], Test Loss: 2.4117\n",
      "Epoch [18/100], Test Loss: 2.3721\n",
      "Epoch [20/100], Test Loss: 2.3815\n",
      "Epoch [22/100], Test Loss: 2.3011\n",
      "Epoch [24/100], Test Loss: 2.2070\n",
      "Epoch [26/100], Test Loss: 2.1034\n",
      "Epoch [28/100], Test Loss: 1.9768\n",
      "Epoch [30/100], Test Loss: 1.7543\n",
      "Epoch [32/100], Test Loss: 1.5286\n",
      "Epoch [34/100], Test Loss: 1.4434\n",
      "Epoch [36/100], Test Loss: 1.3473\n",
      "Epoch [38/100], Test Loss: 1.2988\n",
      "Epoch [40/100], Test Loss: 1.2305\n",
      "Epoch [42/100], Test Loss: 1.2033\n",
      "Epoch [44/100], Test Loss: 1.1271\n",
      "Epoch [46/100], Test Loss: 1.0854\n",
      "Epoch [48/100], Test Loss: 1.0921\n",
      "Epoch [50/100], Test Loss: 1.0696\n",
      "Epoch [52/100], Test Loss: 0.9902\n",
      "Epoch [54/100], Test Loss: 0.9848\n",
      "Epoch [56/100], Test Loss: 0.9299\n",
      "Epoch [58/100], Test Loss: 0.9001\n",
      "Epoch [60/100], Test Loss: 0.8423\n",
      "Epoch [62/100], Test Loss: 0.8377\n",
      "Epoch [64/100], Test Loss: 0.7371\n",
      "Epoch [66/100], Test Loss: 0.7139\n",
      "Epoch [68/100], Test Loss: 0.6766\n",
      "Epoch [70/100], Test Loss: 0.6764\n",
      "Epoch [72/100], Test Loss: 0.6800\n",
      "Epoch [74/100], Test Loss: 0.6218\n",
      "Epoch [76/100], Test Loss: 0.5868\n",
      "Epoch [78/100], Test Loss: 0.5996\n",
      "Epoch [80/100], Test Loss: 0.5511\n",
      "Epoch [82/100], Test Loss: 0.5655\n",
      "Epoch [84/100], Test Loss: 0.5493\n",
      "Epoch [86/100], Test Loss: 0.5153\n",
      "Epoch [88/100], Test Loss: 0.5087\n",
      "Epoch [90/100], Test Loss: 0.4805\n",
      "Epoch [92/100], Test Loss: 0.4540\n",
      "Epoch [94/100], Test Loss: 0.4552\n",
      "Epoch [96/100], Test Loss: 0.4254\n",
      "Epoch [98/100], Test Loss: 0.4364\n",
      "Epoch [100/100], Test Loss: 0.4048\n",
      "\n",
      "Training finished!\n",
      "Training Time: 222.94884848594666 s\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim = 256, output_dim = 1, bounding_box = None):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.hashembedder = HashEmbedder(bounding_box)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope = 0.01)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope = 0.01)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu3 = nn.LeakyReLU(negative_slope = 0.01)\n",
    "        self.fc4 = nn.Linear(hidden_dim,  output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        t = x\n",
    "        t, _ = self.hashembedder(x)\n",
    "        t = self.relu1(self.fc1(t))\n",
    "        t = self.relu2(self.fc2(t))\n",
    "        t = self.relu3(self.fc3(t))\n",
    "        result = self.fc4(t)\n",
    "        return result\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f'Multi-GPU training!')\n",
    "    MLPmodel = nn.DataParallel(SimpleMLP(input_dim = 32, bounding_box = bounding_box))\n",
    "    MLPmodel = MLPmodel.to(Device)\n",
    "else:\n",
    "    print(f'single GPU training: [{Device}]')\n",
    "    MLPmodel = SimpleMLP(input_dim = 32, bounding_box = bounding_box).to(Device)\n",
    "\n",
    "mini_batchSize = 500\n",
    "train_loader = DataLoader(\n",
    "    dataset = TensorDataset(trainDataset_inputs, trainDataset_outputs),\n",
    "    batch_size = mini_batchSize,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(MLPmodel.parameters(), lr = 0.001)\n",
    "mse = nn.MSELoss()\n",
    "num_epochs = 100\n",
    "trainingTime_start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    MLPmodel.train()\n",
    "    for miniBatch_trainingInputs, miniBatch_trainingOutputs in train_loader:\n",
    "        miniBatch_trainingInputs = miniBatch_trainingInputs.to(Device)\n",
    "        miniBatch_trainingOutputs = miniBatch_trainingOutputs.to(Device)\n",
    "        optimizer.zero_grad()\n",
    "        predictedValue = MLPmodel(miniBatch_trainingInputs)\n",
    "        loss = mse(miniBatch_trainingOutputs.unsqueeze(-1), predictedValue)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        MLPmodel.eval()\n",
    "        with torch.no_grad():\n",
    "            predictedValue_testDataset = MLPmodel(testDataset_inputs.to(Device))\n",
    "            test_loss = mse(testDataset_outputs.to(Device).unsqueeze(-1), predictedValue_testDataset)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {test_loss.item():.4f}')\n",
    "trainingTime_end = time.time()\n",
    "print('\\nTraining finished!')\n",
    "print(f'Training Time: {trainingTime_end - trainingTime_start} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2332cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(\"\\nStarting visualization...\")\n",
    "# 设置可视化网格的参数\n",
    "resolution_vis = 50 # 网格点的数量，例如 50x50\n",
    "# 确保 bounding_box 已经定义并移动到正确的设备上\n",
    "# 假设 bounding_box = torch.tensor([[-5, -5, -5], [5, 5, 5]]).to(Device) 已经在前面定义\n",
    "x_coords = torch.linspace(bounding_box[0,0].item(), bounding_box[1,0].item(), resolution_vis)\n",
    "y_coords = torch.linspace(bounding_box[0,1].item(), bounding_box[1,1].item(), resolution_vis)\n",
    "# 创建一个 2D 网格，并固定 z 为 0 （或边界内的任何常数）\n",
    "# 例如，我们固定 z 为 bounding_box 的中心点 z 坐标\n",
    "fixed_z = (bounding_box[0,2] + bounding_box[1,2]) / 2\n",
    "# 使用 meshgrid 创建 x-y 平面上的坐标\n",
    "# xx: resolution_vis x resolution_vis (x 值重复)\n",
    "# yy: resolution_vis x resolution_vis (y 值重复)\n",
    "xx, yy = torch.meshgrid(x_coords, y_coords, indexing='ij') # 使用 'ij' 保持矩阵索引习惯\n",
    "# 将网格展平并组合成 B x 3 的形式\n",
    "# B = resolution_vis * resolution_vis\n",
    "grid_points = torch.stack([xx.flatten(), yy.flatten(), torch.full_like(xx.flatten(), fixed_z)], dim=-1).to(Device)\n",
    "# 将模型设置为评估模式\n",
    "MLPmodel.eval()\n",
    "hashembedder.eval()\n",
    "# 使用 torch.no_grad() 禁用梯度计算，节省内存并加速\n",
    "with torch.no_grad():\n",
    "    # 编码网格点\n",
    "    embedded_grid_points, _ = hashembedder(grid_points)\n",
    "    # 预测函数值\n",
    "    predicted_values = MLPmodel(embedded_grid_points).cpu().numpy()\n",
    "# 将预测值重塑回 2D 网格形式\n",
    "predicted_values_grid = predicted_values.reshape(resolution_vis, resolution_vis)\n",
    "# 计算真实值进行对比\n",
    "true_values = TestFunction(grid_points).cpu().numpy().reshape(resolution_vis, resolution_vis)\n",
    "# 绘制结果\n",
    "plt.figure(figsize=(14, 6))\n",
    "# 绘制真实函数值\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(true_values, origin='lower', extent=[x_coords.min(), x_coords.max(), y_coords.min(), y_coords.max()], cmap='viridis')\n",
    "plt.colorbar(label='True Value')\n",
    "plt.title(f'True Function Value (Z={fixed_z.item():.2f})') # 使用 .item() 获取标量值\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "# 绘制模型预测值\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(predicted_values_grid, origin='lower', extent=[x_coords.min(), x_coords.max(), y_coords.min(), y_coords.max()], cmap='viridis')\n",
    "plt.colorbar(label='Predicted Value')\n",
    "plt.title(f'Predicted Function Value (Z={fixed_z.item():.2f})')\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# 绘制误差图\n",
    "plt.figure(figsize=(7, 6))\n",
    "error_map = np.abs(true_values - predicted_values_grid)\n",
    "plt.imshow(error_map, origin='lower', extent=[x_coords.min(), x_coords.max(), y_coords.min(), y_coords.max()], cmap='Reds')\n",
    "plt.colorbar(label='Absolute Error')\n",
    "plt.title(f'Absolute Error Map (Z={fixed_z.item():.2f})')\n",
    "plt.xlabel('X-coordinate')\n",
    "plt.ylabel('Y-coordinate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HashEmbedder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
